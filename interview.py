import streamlit as st
from utils import (
    navigate_to,
    Add_Back_Img
)

import streamlit as st
from langchain_core.callbacks.base import BaseCallbackHandler
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

import uuid

# ìŠ¤íŠ¸ë¦¬ë° í•´ì£¼ëŠ” í•¨ìˆ˜
class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)







# ì´ì „ ëŒ€í™”ê¸°ë¡ì„ ì¶œë ¥í•´ ì£¼ëŠ” ì½”ë“œ
# role : user, assistant
# message : ëŒ€í™”ë‚´ìš©
def print_messages():
    if "messages" in st.session_state and len(st.session_state["messages"])>0:
        for chat_message in st.session_state["messages"]:
            st.chat_message(chat_message.role).write(chat_message.content)








def interview():
    # ì°½ ìœ„ì— ëœ¨ëŠ” ì•„ì´
    st.set_page_config(page_title="ChatGPT",page_icon="ğŸ¦ˆ")
    st.title("ğŸ¦ˆ JOB AT")


    # session_id : ì¹´í†¡ë°©ëŠë‚Œ, session_idê°€ ë‹¬ë¼ì§€ë©´ ëŒ€í™”ì°½ì´ ë‹¬ë¼ì§
    session_id = str(uuid.uuid4())


    if "cnt" not in st.session_state:
        st.session_state.cnt = 0
    if "next_question" not in st.session_state:
        st.session_state.next_question = 0
    if "interview_stop" not in st.session_state:
        st.session_state.interview_stop = False

    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    # streamlitìœ¼ë¡œ êµ¬í˜„ì„ í•˜ë©´ ì±„íŒ… ì…ë ¥í•  ë•Œë§ˆë‹¤ ì½”ë“œê°€ ì²˜ìŒë¶€í„° ëê¹Œì§€ ë‹¤ì‹œ ì‹¤í–‰ë¨
    # ëŒ€í™”ê¸°ë¡ì„ stateì— ë„£ì–´ì„œ ìºì‹±í•´ì¤€ë‹¤.
    # ì±„íŒ… ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” store ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜
    if "store" not in st.session_state:
        st.session_state["store"] = dict()


    if st.session_state.next_question == 0:
        interview_question = st.session_state.questions[st.session_state.next_question]
        st.session_state["messages"].append(ChatMessage(role="assistant", content=interview_question))
        st.session_state.next_question = 1


    # ì´ì „ ëŒ€í™”ê¸°ë¡ì„ ì¶œë ¥í•´ ì£¼ëŠ” ì½”ë“œ
    print_messages()

    # ì„¸ì…˜  IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    def get_session_history(session_ids:str)->BaseChatMessageHistory:
        if session_ids not in st.session_state["store"]:    # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°
            # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥
            st.session_state["store"][session_ids] = ChatMessageHistory()
        return st.session_state["store"][session_ids]


    # ìœ ì € ì…ë ¥ì´ ìˆì„ë•Œ ìœ ì € ì…ë ¥ì„ ë³´ì—¬ì¤€ë‹¤.
    if user_input:= st.chat_input("ìœ ì €ê°€ ë©”ì„¸ì§€ ì…ë ¥"):
        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
        st.chat_message("user").write(f"{user_input}")
        # st.session_state["messages"].append(("user", user_input))
        st.session_state["messages"].append(ChatMessage(role="user", content=user_input))
        st.session_state.cnt += 1
        if st.session_state.interview_stop == True:
            None

        elif (st.session_state.next_question==len(st.session_state.questions)) & (st.session_state.cnt==3):
            with st.chat_message('assistant'):
                st.write("ë©´ì ‘ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ë©´ì ‘ì— ì‘í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.") # writeì¸ì§€ markdownì¸ì§€ í™•ì¸í•˜ê¸°
                st.session_state.interview_stop = True

        elif st.session_state.cnt == 3:
            st.session_state.cnt = 0
            interview_question = st.session_state.questions[st.session_state.next_question]
            with st.chat_message('assistant'):
                st.write("ë‹µë³€ ê°ì‚¬í•©ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.") # writeì¸ì§€ markdownì¸ì§€ í™•ì¸í•˜ê¸°
                st.write(interview_question)
            st.session_state["messages"].append(ChatMessage(role="assistant", content=interview_question))
            st.session_state.next_question += 1


        else:
            # AIì˜ ë‹µë³€
            with st.chat_message("assistant"):    # "assistant" : streamlitì´ ë§í•¨
                # StreamHandler : í† í° í•˜ë‚˜í•˜ë‚˜ë¥¼ ì¤€ë‹¤.
                stream_handler = StreamHandler(st.empty())
                # 1. ëª¨ë¸ ìƒì„±
                llm = ChatOpenAI(streaming=True, callbacks=[stream_handler])

                # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
                # ì¤‘ê°„ì— ëŒ€í™”ê¸°ë¡ì´ ë“¤ì–´ê°€ì•¼ í•˜ê¸° ë•Œë¬¸ì— ChatPromptTemplate.from_messagesë¥¼ ì‚¬ìš©
                prompt = ChatPromptTemplate.from_messages(
                    [
                        (
                            "system",
                            """ë‹¹ì‹ ì€ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
                            {context}ëŠ” ì‚¬ìš©ìê°€ ë‹µë³€í•´ì•¼í•  ë©´ì ‘ ì§ˆë¬¸ì…ë‹ˆë‹¤.
                            ì‚¬ìš©ìì˜ ë‹µë³€ì— ëŒ€í•´ ê¼¬ë¦¬ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.
                            ì‚¬ìš©ìì˜ ë‹µë³€ì— ëŒ€í•œ ë¶€ê°€ì„¤ëª…ì€ í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”.
                            ë§Œì•½ ì‚¬ìš©ìê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì—†ëŠ” ë‹µë³€ì„ í•œë‹¤ë©´ ì§€ì í•´ì£¼ì„¸ìš”.
                            """,
                        ),
                        # ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©, historyê°€ MessageHistory ì˜ key ê°€ ë¨
                        MessagesPlaceholder(variable_name="history"),
                        ("human", "{question}"),   # ì‚¬ìš©ì ì§ˆë¬¸ì„ ì…ë ¥
                    ]
                )

                chain = prompt | llm   # í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ runnable ê°ì²´ ìƒì„±

                chain_with_memory = (
                    RunnableWithMessageHistory( # RunnableWithMessageHistory ê°ì²´ ìƒì„±
                        chain,   # ìƒì„±í•  Runnable ê°ì²´
                        get_session_history,    # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
                        input_messages_key="question", # ì‚¬ìš©ì ì§ˆë¬¸ì˜ í‚¤
                        history_messages_key="history", # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤
                    )
                )
                interview_question = st.session_state.questions[(st.session_state.next_question)-1]
                response = chain_with_memory.invoke(
                    {"context" : interview_question,"question":user_input},
                    # ì„¸ì…˜ IDë¥¼ ì„¤ì • 
                    config={"configurable":{"session_id":session_id}},
                )
                msg = response.content
                # st.session_state["messages"].append(("assistant", msg))
                st.session_state["messages"].append(ChatMessage(role="assistant", content=msg))







    with st.sidebar:
        main = st.button("Home í™”ë©´", use_container_width=True)
        if(main):
            navigate_to("main")
        prev = st.button("ì§ˆë¬¸ ë‹¤ì‹œ ë³´ê¸°", use_container_width=True)
        if(prev):
            navigate_to("view_question")


