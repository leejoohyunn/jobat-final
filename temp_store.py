import streamlit as st
from utils import (
    navigate_to,
    Add_Back_Img
)

import streamlit as st
from langchain_core.callbacks.base import BaseCallbackHandler
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory



# ìŠ¤íŠ¸ë¦¬ë° í•´ì£¼ëŠ” í•¨ìˆ˜
class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)




# ì´ì „ ëŒ€í™”ê¸°ë¡ì„ ì¶œë ¥í•´ ì£¼ëŠ” ì½”ë“œ
# role : user, assistant
# message : ëŒ€í™”ë‚´ìš©
# def print_messages():
#     if "messages" in st.session_state and len(st.session_state["messages"])>0:
#         for role, message in st.session_state["messages"]:
#             st.chat_message(role).write(message)

def print_messages():
    if "messages" in st.session_state and len(st.session_state["messages"])>0:
        for chat_message in st.session_state["messages"]:
            st.chat_message(chat_message.role).write(chat_message.content)



def interview():
    # ì°½ ìœ„ì— ëœ¨ëŠ” ì•„ì´
    st.set_page_config(page_title="ChatGPT",page_icon="ğŸ¦ˆ")
    st.title("ğŸ¦ˆ JOB AT")

    if "cnt" not in st.session_state:
        st.session_state.cnt = 0

    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    # streamlitìœ¼ë¡œ êµ¬í˜„ì„ í•˜ë©´ ì±„íŒ… ì…ë ¥í•  ë•Œë§ˆë‹¤ ì½”ë“œê°€ ì²˜ìŒë¶€í„° ëê¹Œì§€ ë‹¤ì‹œ ì‹¤í–‰ë¨
    # ëŒ€í™”ê¸°ë¡ì„ stateì— ë„£ì–´ì„œ ìºì‹±í•´ì¤€ë‹¤.
    # ì±„íŒ… ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” store ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜
    if "store" not in st.session_state:
        st.session_state["store"] = dict()

    # ì´ì „ ëŒ€í™”ê¸°ë¡ì„ ì¶œë ¥í•´ ì£¼ëŠ” ì½”ë“œ
    print_messages()

    # ì„¸ì…˜  IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    def get_session_history(session_ids:str)->BaseChatMessageHistory:
        # print(session_ids)
        if session_ids not in st.session_state["store"]:    # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°
            # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥
            st.session_state["store"][session_ids] = ChatMessageHistory()
        return st.session_state["store"][session_ids]


    # ìœ ì € ì…ë ¥ì´ ìˆì„ë•Œ ìœ ì € ì…ë ¥ì„ ë³´ì—¬ì¤€ë‹¤.
    if user_input:= st.chat_input("ìœ ì €ê°€ ë©”ì„¸ì§€ ì…ë ¥"):
        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
        st.chat_message("user").write(f"{user_input}")
        # st.session_state["messages"].append(("user", user_input))
        st.session_state["messages"].append(ChatMessage(role="user", content=user_input))

        # # LLM ì„ ì‚¬ìš©í•˜ì—¬ AIë‹µë³€ì„ ìƒì„±
        # prompt = ChatPromptTemplate.from_template(
        #     """ì§ˆë¬¸ì— ëŒ€í•˜ì—¬ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
        #     {question}
        #     """
        # )

        # chain = prompt | ChatOpenAI()
        # response = chain.invoke({"question": user_input})
        # msg = response.content

        # chain = prompt | ChatOpenAI() | StrOutputParser()
        # msg = chain.invoke({"question": user_input})


        # AIì˜ ë‹µë³€
        with st.chat_message("assistant"):    # "assistant" : streamlitì´ ë§í•¨
            # StreamHandler : í† í° í•˜ë‚˜í•˜ë‚˜ë¥¼ ì¤€ë‹¤.
            stream_handler = StreamHandler(st.empty())
            # 1. ëª¨ë¸ ìƒì„±
            llm = ChatOpenAI(streaming=True, callbacks=[stream_handler])

            # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
            # ì¤‘ê°„ì— ëŒ€í™”ê¸°ë¡ì´ ë“¤ì–´ê°€ì•¼ í•˜ê¸° ë•Œë¬¸ì— ChatPromptTemplate.from_messagesë¥¼ ì‚¬ìš©
            prompt = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        "ì§ˆë¬¸ì— ì§§ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.",
                    ),
                    # ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©, historyê°€ MessageHistory ì˜ key ê°€ ë¨
                    MessagesPlaceholder(variable_name="history"),
                    ("human", "{question}"),   # ì‚¬ìš©ì ì§ˆë¬¸ì„ ì…ë ¥
                ]
            )

            chain = prompt | llm   # í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ runnable ê°ì²´ ìƒì„±

            chain_with_memory = (
                RunnableWithMessageHistory( # RunnableWithMessageHistory ê°ì²´ ìƒì„±
                    chain,   # ìƒì„±í•  Runnable ê°ì²´
                    get_session_history,    # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
                    input_messages_key="question", # ì‚¬ìš©ì ì§ˆë¬¸ì˜ í‚¤
                    history_messages_key="history", # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤
                )
            )

            response = chain_with_memory.invoke(
                {"question":user_input},
                # ì„¸ì…˜ IDë¥¼ ì„¤ì • 
                config={"configurable":{"session_id":session_id}},
            )
            msg = response.content
            # msg = "ë‹¹ì‹ ì´ ì…ë ¥í•œ ë‚´ìš©: {user_input}"
            # st.write(msg)
            # st.session_state["messages"].append(("assistant", msg))
            st.session_state["messages"].append(
                ChatMessage(role="assistant", content=msg)
            )
            st.session_state.cnt += 1


    with st.sidebar:
        main = st.button("Home í™”ë©´", use_container_width=True)
        if(main):
            navigate_to("main")
        prev = st.button("ì§ˆë¬¸ ë‹¤ì‹œ ë³´ê¸°", use_container_width=True)
        if(prev):
            navigate_to("view_question")


